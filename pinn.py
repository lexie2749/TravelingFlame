import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from torch.autograd import grad
import time

class StableCombustionPINN(nn.Module):
    """
    æ•°å€¼ç¨³å®šçš„ç‡ƒçƒ§PINN - ä¿®å¤æ— ç©·å¤§æŸå¤±é—®é¢˜
    """
    def __init__(self, layers, activation=torch.tanh):
        super(StableCombustionPINN, self).__init__()
        
        self.layers = nn.ModuleList()
        for i in range(len(layers) - 1):
            self.layers.append(nn.Linear(layers[i], layers[i+1]))
        
        self.activation = activation
        
        # æ— é‡çº²å‚æ•°
        self.Reynolds = 100.0
        self.Peclet = 50.0        # å‡å°Pecletæ•°ï¼Œå¢žå¼ºæ‰©æ•£
        self.Schmidt = 1.0
        self.Damkohler = 5.0      # å‡å°ååº”å¼ºåº¦
        self.heat_release = 2.0   # å‡å°çƒ­é‡Šæ”¾
        
        self.init_weights()
    
    def init_weights(self):
        """ç¨³å®šçš„æƒé‡åˆå§‹åŒ–"""
        for i, layer in enumerate(self.layers):
            if i == len(self.layers) - 1:  # è¾“å‡ºå±‚
                nn.init.uniform_(layer.weight, -0.05, 0.05)  # æ›´å°çš„æƒé‡
                with torch.no_grad():
                    layer.bias[0] = 0.5   # u
                    layer.bias[1] = 0.0   # v  
                    layer.bias[2] = 0.0   # p
                    layer.bias[3] = 0.5   # T (æ­£æ•°åç½®)
                    layer.bias[4] = 0.5   # Y (æ­£æ•°åç½®)
            else:
                nn.init.xavier_normal_(layer.weight, gain=0.5)
                nn.init.zeros_(layer.bias)
    
    def forward(self, x, t):
        """
        å‰å‘ä¼ æ’­ - ä½¿ç”¨æ¸©å’Œçš„çº¦æŸé˜²æ­¢æ•°å€¼é—®é¢˜
        """
        inputs = torch.cat([x, t], dim=1)
        
        for layer in self.layers[:-1]:
            inputs = self.activation(layer(inputs))
        
        outputs = self.layers[-1](inputs)
        
        # æ¸©å’Œçš„è¾“å‡ºçº¦æŸ - é˜²æ­¢æžç«¯å€¼ä½†ä¿æŒå¯å­¦ä¹ æ€§
        u = torch.tanh(outputs[:, 0:1]) * 3.0           # é€Ÿåº¦èŒƒå›´[-3, 3]
        v = torch.tanh(outputs[:, 1:2]) * 1.0           # èŒƒå›´[-1, 1]
        p = torch.tanh(outputs[:, 2:3]) * 2.0           # åŽ‹åŠ›èŒƒå›´[-2, 2]
        
        # å…³é”®ä¿®å¤ï¼šç¡®ä¿æ¸©åº¦å’Œç‡ƒæ–™æµ“åº¦ä¸ºæ­£
        T_raw = outputs[:, 3:4]
        T = 0.1 + torch.nn.functional.softplus(T_raw)   # T â‰¥ 0.1ï¼Œé¿å…è´Ÿæ¸©åº¦
        
        Y_raw = outputs[:, 4:5]
        Y_fuel = torch.sigmoid(Y_raw)                   # Y âˆˆ [0, 1]
        
        return u, v, p, T, Y_fuel
    
    def safe_reaction_rate(self, T, Y_fuel):
        """
        æ•°å€¼ç¨³å®šçš„ååº”é€ŸçŽ‡è®¡ç®—
        """
        # ç¡®ä¿è¾“å…¥åœ¨å®‰å…¨èŒƒå›´å†…
        T_safe = torch.clamp(T, min=0.1, max=10.0)      # é˜²æ­¢æžç«¯æ¸©åº¦
        Y_safe = torch.clamp(Y_fuel, min=1e-6, max=1.0) # é˜²æ­¢é›¶æµ“åº¦
        
        # æ”¹è¿›çš„ååº”é€ŸçŽ‡æ¨¡åž‹
        T_ignition = 0.8  # ç‚¹ç«æ¸©åº¦
        
        # ä½¿ç”¨æ›´ç¨³å®šçš„Arrheniuså½¢å¼
        # rate = A * Y * exp(-Ea/RT)ï¼Œä½†é™åˆ¶æŒ‡æ•°èŒƒå›´
        activation_term = -2.0 / T_safe  # ç®€åŒ–çš„æ´»åŒ–èƒ½é¡¹
        activation_term = torch.clamp(activation_term, min=-10, max=10)  # é™åˆ¶æŒ‡æ•°èŒƒå›´
        
        # ååº”é€ŸçŽ‡
        rate = self.Damkohler * Y_safe * torch.exp(activation_term)
        
        # å¹³æ»‘çš„ç‚¹ç«å¼€å…³
        ignition_factor = torch.sigmoid((T_safe - T_ignition) * 10.0)
        
        # ç¡®ä¿ååº”é€ŸçŽ‡æœ‰ç•Œ
        final_rate = rate * ignition_factor
        final_rate = torch.clamp(final_rate, min=0.0, max=100.0)  # é™åˆ¶æœ€å¤§ååº”é€ŸçŽ‡
        
        return final_rate
    
    def stable_physics_loss(self, x, t):
        """
        æ•°å€¼ç¨³å®šçš„ç‰©ç†æŸå¤±è®¡ç®—
        """
        x.requires_grad_(True)
        t.requires_grad_(True)
        
        u, v, p, T, Y_fuel = self.forward(x, t)
        
        # æ›´å®‰å…¨çš„æ¢¯åº¦è®¡ç®—
        def compute_gradient(output, input_var, create_graph=True):
            try:
                grad_val = grad(output, input_var, 
                              grad_outputs=torch.ones_like(output),
                              create_graph=create_graph, 
                              retain_graph=True,
                              allow_unused=True)[0]
                
                if grad_val is None:
                    return torch.zeros_like(input_var)
                
                # æ£€æŸ¥å¹¶å¤„ç†å¼‚å¸¸å€¼
                grad_val = torch.where(torch.isnan(grad_val), 
                                     torch.zeros_like(grad_val), grad_val)
                grad_val = torch.where(torch.isinf(grad_val), 
                                     torch.zeros_like(grad_val), grad_val)
                grad_val = torch.clamp(grad_val, min=-1e6, max=1e6)
                
                return grad_val
            except:
                return torch.zeros_like(input_var)
        
        # è®¡ç®—æ¢¯åº¦
        u_x = compute_gradient(u, x)
        u_t = compute_gradient(u, t)
        v_x = compute_gradient(v, x)
        v_t = compute_gradient(v, t)
        p_x = compute_gradient(p, x)
        T_x = compute_gradient(T, x)
        T_t = compute_gradient(T, t)
        Y_x = compute_gradient(Y_fuel, x)
        Y_t = compute_gradient(Y_fuel, t)
        
        # äºŒé˜¶å¯¼æ•°
        u_xx = compute_gradient(u_x, x)
        v_xx = compute_gradient(v_x, x)
        T_xx = compute_gradient(T_x, x)
        Y_xx = compute_gradient(Y_x, x)
        
        # ç¨³å®šçš„ååº”é€ŸçŽ‡
        omega = self.safe_reaction_rate(T, Y_fuel)
        
        # æŽ§åˆ¶æ–¹ç¨‹ï¼ˆæ·»åŠ æ•°å€¼æ£€æŸ¥ï¼‰
        def safe_equation(expr, name=""):
            result = expr
            # æ£€æŸ¥å¹¶æ›¿æ¢å¼‚å¸¸å€¼
            result = torch.where(torch.isnan(result), torch.zeros_like(result), result)
            result = torch.where(torch.isinf(result), torch.zeros_like(result), result)
            result = torch.clamp(result, min=-1e6, max=1e6)
            return result
        
        # 1. è¿žç»­æ€§æ–¹ç¨‹
        continuity = safe_equation(u_x, "continuity")
        
        # 2. åŠ¨é‡æ–¹ç¨‹
        momentum_u = safe_equation(
            u_t + u * u_x + p_x - (1.0/self.Reynolds) * u_xx, "momentum_u")
        momentum_v = safe_equation(
            v_t + u * v_x - (1.0/self.Reynolds) * v_xx, "momentum_v")
        
        # 3. èƒ½é‡æ–¹ç¨‹ï¼ˆå…³é”®ä¿®å¤ï¼‰
        energy = safe_equation(
            T_t + u * T_x - (1.0/self.Peclet) * T_xx - self.heat_release * omega, "energy")
        
        # 4. ç»„åˆ†æ–¹ç¨‹ï¼ˆå…³é”®ä¿®å¤ï¼‰
        species = safe_equation(
            Y_t + u * Y_x - (1.0/self.Schmidt) * Y_xx + omega, "species")
        
        return continuity, momentum_u, momentum_v, energy, species

class StableTrainer:
    """æ•°å€¼ç¨³å®šçš„è®­ç»ƒå™¨"""
    def __init__(self, model, domain_bounds, device='cpu'):
        self.model = model.to(device)
        self.device = device
        self.domain_bounds = domain_bounds
        
        # ä¿å®ˆçš„ä¼˜åŒ–å™¨è®¾ç½®
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=5e-4)
        
        self.loss_history = []
        self.gradient_norms = []
        
    def generate_training_data(self, n_points=1500):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        x_min, x_max, t_min, t_max = self.domain_bounds
        
        # å†…éƒ¨ç‚¹
        x_int = torch.rand(n_points, 1) * (x_max - x_min) + x_min
        t_int = torch.rand(n_points, 1) * (t_max - t_min) + t_min
        
        # è¾¹ç•Œç‚¹
        n_bc = n_points // 5
        x_bc_left = torch.zeros(n_bc, 1) + x_min
        x_bc_right = torch.ones(n_bc, 1) * x_max
        t_bc = torch.rand(2*n_bc, 1) * (t_max - t_min) + t_min
        x_bc = torch.cat([x_bc_left, x_bc_right])
        
        # åˆå§‹ç‚¹
        n_ic = n_points // 5
        x_ic = torch.rand(n_ic, 1) * (x_max - x_min) + x_min
        t_ic = torch.zeros(n_ic, 1) + t_min
        
        return (x_int.to(self.device), t_int.to(self.device),
                x_bc.to(self.device), t_bc.to(self.device),
                x_ic.to(self.device), t_ic.to(self.device))
    
    def train_step(self, x_int, t_int, x_bc, t_bc, x_ic, t_ic, epoch):
        """ç¨³å®šçš„è®­ç»ƒæ­¥éª¤"""
        self.optimizer.zero_grad()
        
        # ç‰©ç†æŸå¤±
        cont_loss, mom_u_loss, mom_v_loss, energy_loss, species_loss = \
            self.model.stable_physics_loss(x_int, t_int)
        
        # è®¡ç®—å„é¡¹æŸå¤±å¹¶æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
        def safe_loss(tensor_loss, name):
            loss_val = torch.mean(tensor_loss**2)
            if torch.isnan(loss_val) or torch.isinf(loss_val):
                print(f"  âš ï¸  {name}æŸå¤±å¼‚å¸¸: {loss_val}")
                return torch.tensor(0.0, device=self.device)
            return loss_val
        
        cont_val = safe_loss(cont_loss, "è¿žç»­æ€§")
        mom_u_val = safe_loss(mom_u_loss, "åŠ¨é‡u")
        mom_v_val = safe_loss(mom_v_loss, "åŠ¨é‡v")
        energy_val = safe_loss(energy_loss, "èƒ½é‡")
        species_val = safe_loss(species_loss, "ç»„åˆ†")
        
        physics_loss = cont_val + mom_u_val + mom_v_val + energy_val + species_val
        
        # è¾¹ç•Œæ¡ä»¶
        u_bc, v_bc, p_bc, T_bc, Y_bc = self.model(x_bc, t_bc)
        
        n_left = len(x_bc) // 2
        # å·¦è¾¹ç•Œï¼ˆå…¥å£ï¼‰
        u_inlet = torch.ones(n_left, 1, device=self.device) * 2.0
        T_inlet = torch.ones(n_left, 1, device=self.device) * 2.0    # é«˜æ¸©
        Y_inlet = torch.ones(n_left, 1, device=self.device) * 0.9    # é«˜ç‡ƒæ–™æµ“åº¦
        
        # å³è¾¹ç•Œï¼ˆå‡ºå£ï¼‰
        u_outlet = torch.ones(n_left, 1, device=self.device) * 1.0
        T_outlet = torch.ones(n_left, 1, device=self.device) * 0.5   # ä½Žæ¸©
        Y_outlet = torch.ones(n_left, 1, device=self.device) * 0.1   # ä½Žç‡ƒæ–™æµ“åº¦
        
        bc_loss = (torch.mean((u_bc[:n_left] - u_inlet)**2) +
                  torch.mean((T_bc[:n_left] - T_inlet)**2) +
                  torch.mean((Y_bc[:n_left] - Y_inlet)**2) +
                  torch.mean((u_bc[n_left:] - u_outlet)**2) +
                  torch.mean((T_bc[n_left:] - T_outlet)**2) +
                  torch.mean((Y_bc[n_left:] - Y_outlet)**2))
        
        # åˆå§‹æ¡ä»¶
        u_ic, v_ic, p_ic, T_ic, Y_ic = self.model(x_ic, t_ic)
        
        # åˆ›å»ºç©ºé—´å˜åŒ–çš„åˆå§‹æ¡ä»¶
        T_init = 0.3 + 1.5 * torch.exp(-((x_ic - 0.3) / 0.15)**2)  # é«˜æ–¯çƒ­ç‚¹
        Y_init = 0.8 * torch.ones_like(x_ic)  # å‡åŒ€ç‡ƒæ–™åˆ†å¸ƒ
        u_init = 1.0 * torch.ones_like(x_ic)  # åˆå§‹æµé€Ÿ
        
        ic_loss = (torch.mean((u_ic - u_init)**2) +
                  torch.mean((T_ic - T_init)**2) +
                  torch.mean((Y_ic - Y_init)**2))
        
        # æ€»æŸå¤±
        total_loss = physics_loss + 2.0 * bc_loss + 5.0 * ic_loss
        
        # æ£€æŸ¥æ€»æŸå¤±
        if torch.isnan(total_loss) or torch.isinf(total_loss) or total_loss > 1e4:
            print(f"  âš ï¸  æ€»æŸå¤±å¼‚å¸¸: {total_loss:.2f}, è·³è¿‡æ›´æ–°")
            return float('inf'), float('inf'), float('inf'), float('inf')
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_norm = 0
        for p in self.model.parameters():
            if p.grad is not None:
                param_norm = p.grad.data.norm(2)
                grad_norm += param_norm.item() ** 2
        grad_norm = grad_norm ** (1. / 2)
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        self.optimizer.step()
        self.gradient_norms.append(grad_norm)
        
        if epoch % 50 == 0:  # è¯¦ç»†è¾“å‡º
            print(f"  ðŸ“Š æŸå¤±è¯¦æƒ…:")
            print(f"    è¿žç»­æ€§: {cont_val:.6f}")
            print(f"    åŠ¨é‡u: {mom_u_val:.6f}")
            print(f"    åŠ¨é‡v: {mom_v_val:.6f}")
            print(f"    èƒ½é‡: {energy_val:.6f}")
            print(f"    ç»„åˆ†: {species_val:.6f}")
            print(f"    è¾¹ç•Œ: {bc_loss:.6f}")
            print(f"    åˆå§‹: {ic_loss:.6f}")
            print(f"    æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}")
        
        return total_loss.item(), physics_loss.item(), bc_loss.item(), ic_loss.item()
    
    def train(self, epochs=1000, print_freq=100):
        """ç¨³å®šè®­ç»ƒå¾ªçŽ¯"""
        print("ðŸ”§ å¼€å§‹æ•°å€¼ç¨³å®šè®­ç»ƒ...")
        
        consecutive_failures = 0
        
        for epoch in range(epochs):
            if epoch % 30 == 0:  # é¢‘ç¹é‡æ–°é‡‡æ ·
                x_int, t_int, x_bc, t_bc, x_ic, t_ic = self.generate_training_data()
            
            total_loss, physics_loss, bc_loss, ic_loss = self.train_step(
                x_int, t_int, x_bc, t_bc, x_ic, t_ic, epoch)
            
            # æ£€æŸ¥è®­ç»ƒå¤±è´¥
            if np.isinf(total_loss):
                consecutive_failures += 1
                if consecutive_failures > 10:
                    print("âŒ è¿žç»­è®­ç»ƒå¤±è´¥ï¼Œé‡æ–°åˆå§‹åŒ–...")
                    self.model.init_weights()
                    consecutive_failures = 0
            else:
                consecutive_failures = 0
                self.loss_history.append([total_loss, physics_loss, bc_loss, ic_loss])
            
            if epoch % print_freq == 0:
                print(f"\nðŸ“Š Epoch {epoch}/{epochs}")
                if not np.isinf(total_loss):
                    print(f"  âœ… æ€»æŸå¤±: {total_loss:.6f}")
                    
                    # æ£€æŸ¥å­¦ä¹ è¿›å±•
                    with torch.no_grad():
                        x_test = torch.tensor([[0.1], [0.5], [0.9]], device=self.device)
                        t_test = torch.tensor([[0.05], [0.05], [0.05]], device=self.device)
                        u, v, p, T, Y = self.model(x_test, t_test)
                        
                        print(f"  ðŸ” è¾“å‡ºæ£€æŸ¥:")
                        print(f"    æ¸©åº¦èŒƒå›´: [{T.min():.3f}, {T.max():.3f}]")
                        print(f"    ç‡ƒæ–™èŒƒå›´: [{Y.min():.3f}, {Y.max():.3f}]")
                        print(f"    é€Ÿåº¦èŒƒå›´: [{u.min():.3f}, {u.max():.3f}]")
                else:
                    print(f"  âŒ è®­ç»ƒå¤±è´¥ (ç¬¬{consecutive_failures}æ¬¡)")
                
                print("-" * 50)
    
    def predict(self, x_test, t_test):
        """é¢„æµ‹"""
        self.model.eval()
        with torch.no_grad():
            x_test = torch.tensor(x_test, dtype=torch.float32).to(self.device)
            t_test = torch.tensor(t_test, dtype=torch.float32).to(self.device)
            
            if x_test.dim() == 1:
                x_test = x_test.unsqueeze(1)
            if t_test.dim() == 1:
                t_test = t_test.unsqueeze(1)
            
            u, v, p, T, Y_fuel = self.model(x_test, t_test)
            
        return (u.cpu().numpy(), v.cpu().numpy(), p.cpu().numpy(), 
                T.cpu().numpy(), Y_fuel.cpu().numpy())
    
    def plot_results(self):
        """ç»˜åˆ¶æœ€ç»ˆç»“æžœ"""
        x_test = np.linspace(0, 1, 100)
        t_test = np.full_like(x_test, 0.05)
        
        u, v, p, T, Y = self.predict(x_test, t_test)
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # å„å˜é‡æ²¿xçš„åˆ†å¸ƒ
        axes[0,0].plot(x_test, u.flatten(), 'b-', linewidth=2)
        axes[0,0].set_title('x-Velocity')
        axes[0,0].set_xlabel('x')
        axes[0,0].grid(True)
        
        axes[0,1].plot(x_test, T.flatten(), 'r-', linewidth=2)
        axes[0,1].set_title('Temperature')
        axes[0,1].set_xlabel('x')
        axes[0,1].grid(True)
        
        axes[0,2].plot(x_test, Y.flatten(), 'g-', linewidth=2)
        axes[0,2].set_title('Fuel Mass Fraction')
        axes[0,2].set_xlabel('x')
        axes[0,2].grid(True)
        
        axes[1,0].plot(x_test, p.flatten(), 'm-', linewidth=2)
        axes[1,0].set_title('Pressure')
        axes[1,0].set_xlabel('x')
        axes[1,0].grid(True)
        
        # æŸå¤±åŽ†å²
        if len(self.loss_history) > 0:
            loss_array = np.array(self.loss_history)
            axes[1,1].semilogy(loss_array[:, 0], 'b-', label='Total', linewidth=2)
            axes[1,1].semilogy(loss_array[:, 1], 'r-', label='Physics', alpha=0.7)
            axes[1,1].semilogy(loss_array[:, 2], 'g-', label='Boundary', alpha=0.7)
            axes[1,1].semilogy(loss_array[:, 3], 'm-', label='Initial', alpha=0.7)
            axes[1,1].set_title('Loss History')
            axes[1,1].set_xlabel('Epoch')
            axes[1,1].set_ylabel('Loss')
            axes[1,1].legend()
            axes[1,1].grid(True)
        
        # æ•°å€¼æ€»ç»“
        axes[1,2].axis('off')
        summary = f"""
Numerical Summary:

Temperature: [{T.min():.3f}, {T.max():.3f}]
Variation: {T.max() - T.min():.3f}

Fuel: [{Y.min():.3f}, {Y.max():.3f}]
Variation: {Y.max() - Y.min():.3f}

Velocity: [{u.min():.3f}, {u.max():.3f}]
Variation: {u.max() - u.min():.3f}

Final Loss: {self.loss_history[-1][0]:.6f}
"""
        axes[1,2].text(0.1, 0.5, summary, fontsize=12, 
                      verticalalignment='center', fontfamily='monospace')
        
        plt.tight_layout()
        plt.show()
        
        print(f"\n{'='*60}")
        print("Stable Training Results")
        print(f"{'='*60}")
        print(f"Temperature variation: {T.max() - T.min():.6f}")
        print(f"Fuel variation: {Y.max() - Y.min():.6f}")
        print(f"Velocity variation: {u.max() - u.min():.6f}")
        print(f"Final loss: {self.loss_history[-1][0]:.6f}")
        
        if (T.max() - T.min()) > 0.2 and (Y.max() - Y.min()) > 0.2:
            print("SUCCESS: Network learned combustion physics!")
        else:
            print("PARTIAL: Limited learning detected")
        print(f"{'='*60}")

def main():
    """ä¸»å‡½æ•°"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Device: {device}")
    
    layers = [2, 64, 64, 64, 5]
    
    model = StableCombustionPINN(layers)
    domain_bounds = [0.0, 1.0, 0.0, 0.1]
    trainer = StableTrainer(model, domain_bounds, device)
    
    print("\nKey Fixes Applied:")
    print("âœ… Temperature constrained to be positive (T â‰¥ 0.1)")
    print("âœ… Fuel fraction constrained to [0,1] with sigmoid")
    print("âœ… Reaction rate with numerical bounds")
    print("âœ… Safe gradient computation with NaN/Inf checks")
    print("âœ… Equation stabilization with value clamping")
    print("âœ… Automatic reinitialization on training failure")
    print("âœ… Reduced reaction parameters for stability")
    print("-" * 60)
    
    trainer.train(epochs=800, print_freq=100)
    trainer.plot_results()

if __name__ == "__main__":
    main()